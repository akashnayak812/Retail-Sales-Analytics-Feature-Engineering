{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Retail Sales Analytics & Feature Engineering\n\n## üß© PROJECT GOAL\nThis project aims to build an end-to-end data analytics workflow. The key steps include generating a retail sales dataset, cleaning and validating the data, performing feature engineering, conducting exploratory data analysis (EDA), and finally deriving actionable insights and recommendations. Optionally, a simple predictive model is trained."]},{"cell_type":"markdown","metadata":{},"source":["### 1Ô∏è‚É£ Import Libraries\nFirst, we import all the necessary Python libraries for data manipulation, numerical operations, visualization, and machine learning."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\n\n# Set plot style\nsns.set_style('whitegrid')\nplt.rcParams['figure.figsize'] = (12, 6)"]},{"cell_type":"markdown","metadata":{},"source":["### 2Ô∏è‚É£ Generate Dataset\nWe'll create a synthetic dataset that mimics real-world retail sales data, including common issues like missing values and incorrect entries. This allows us to demonstrate the entire data cleaning and analysis pipeline."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def generate_sales_data(num_rows=10000):\n    \"\"\"Generates a synthetic retail sales DataFrame.\"\"\"\n    # Create lists of possible values\n    regions = ['North', 'South', 'East', 'West']\n    payment_methods = ['Credit Card', 'Debit Card', 'Online', 'Cash']\n    categories = {\n        'Electronics': [f'E{101+i}' for i in range(5)],\n        'Apparel': [f'A{201+i}' for i in range(5)],\n        'Home Goods': [f'H{301+i}' for i in range(5)],\n        'Groceries': [f'G{401+i}' for i in range(5)]\n    }\n    all_products = [p for sublist in categories.values() for p in sublist]\n    product_to_category = {p: cat for cat, prods in categories.items() for p in prods}\n\n    # Generate data\n    data = {\n        'TransactionID': range(1, num_rows + 1),\n        'CustomerID': [f'C{np.random.randint(100, 500)}' for _ in range(num_rows)],\n        'ProductID': np.random.choice(all_products, num_rows),\n        'Quantity': np.random.randint(-5, 21, num_rows),\n        'UnitPrice': np.round(np.random.uniform(10.5, 500.5, num_rows), 2),\n        'Discount': np.random.choice([0, 5, 10, 15, 20], num_rows, p=[0.5, 0.2, 0.15, 0.1, 0.05]),\n        'Region': np.random.choice(regions, num_rows),\n        'Date': pd.to_datetime(np.random.choice(pd.date_range('2022-01-01', '2023-12-31'), num_rows)),\n        'PaymentMethod': np.random.choice(payment_methods, num_rows)\n    }\n    df = pd.DataFrame(data)\n    df['Category'] = df['ProductID'].map(product_to_category)\n\n    # Introduce missing CustomerIDs\n    missing_indices = df.sample(frac=0.05, random_state=42).index\n    df.loc[missing_indices, 'CustomerID'] = np.nan\n    \n    # Ensure there are some zero quantities which will be removed later\n    zero_qty_indices = df.sample(frac=0.02, random_state=42).index\n    df.loc[zero_qty_indices, 'Quantity'] = 0\n\n    # Reorder columns for clarity\n    cols_order = ['TransactionID', 'CustomerID', 'ProductID', 'Category', 'Quantity', 'UnitPrice', \n                  'Discount', 'Region', 'Date', 'PaymentMethod']\n    df = df[cols_order]\n    \n    return df\n\n# Generate and save the raw dataset\ndf_raw = generate_sales_data()\ndf_raw.to_csv('retail_sales.csv', index=False)\n\nprint("Dataset generated with shape:", df_raw.shape)\nprint("Initial data sample:")\ndf_raw.head()"]},{"cell_type":"markdown","metadata":{},"source":["### 3Ô∏è‚É£ Data Cleaning & Validation\nIn this step, we address data quality issues. We'll handle missing `CustomerID`s, separate invalid transactions (like returns), and ensure data types are correct."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Load the dataset to simulate a real-world scenario\ndf = pd.read_csv('retail_sales.csv')\n\n# -- Data Cleaning Steps --\n\n# 1. Handle missing CustomerID\nprint(f"Missing CustomerIDs before cleaning: {df['CustomerID'].isnull().sum()}")\ndf['CustomerID'].fillna('Guest', inplace=True)\nprint(f"Missing CustomerIDs after cleaning: {df['CustomerID'].isnull().sum()}")\n\n# 2. Separate returns (negative or zero quantity)\nreturns_df = df[df['Quantity'] <= 0].copy()\ndf_clean = df[df['Quantity'] > 0].copy()\n\nprint(f"\nOriginal transactions: {len(df)}")\nprint(f"Valid sales transactions: {len(df_clean)}")\nprint(f"Returned/Invalid transactions: {len(returns_df)}")\n\n# 3. Validate data types\ndf_clean['Date'] = pd.to_datetime(df_clean['Date'])\n\nprint("\nData types after validation:")\ndf_clean.info()"]},{"cell_type":"markdown","metadata":{},"source":["### 4Ô∏è‚É£ Feature Engineering\nNow, we derive new features from the existing data. This enriches the dataset and provides more variables for analysis and modeling.\n\n- **Derived Features:** `TotalValue` is calculated from price, quantity, and discount.\n- **Temporal Features:** We extract `Year`, `Month`, `DayOfWeek`, and `IsWeekend` from the `Date` column.\n- **Aggregated Features:** We create a customer-level summary to understand purchasing behavior."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 1. TotalValue Calculation\ndf_clean['TotalValue'] = df_clean['Quantity'] * df_clean['UnitPrice'] * (1 - df_clean['Discount'] / 100)\n\n# 2. Temporal Features\ndf_clean['Year'] = df_clean['Date'].dt.year\ndf_clean['Month'] = df_clean['Date'].dt.to_period('M')\ndf_clean['DayOfWeek'] = df_clean['Date'].dt.day_name()\ndf_clean['IsWeekend'] = df_clean['Date'].dt.dayofweek.isin([5, 6]).astype(int)\n\n# 3. Customer-Level Metrics (excluding 'Guest')\ncustomer_df = df_clean[df_clean['CustomerID'] != 'Guest']\ncustomer_summary = customer_df.groupby('CustomerID').agg(\n    TotalSpent=('TotalValue', 'sum'),\n    AvgSpend=('TotalValue', 'mean'),\n    Transactions=('TransactionID', 'count')\n).reset_index()\n\nprint("Cleaned data with new features:")\ndisplay(df_clean.head())\n\nprint("\nCustomer-level summary:")\ndisplay(customer_summary.head())"]},{"cell_type":"markdown","metadata":{},"source":["### 5Ô∏è‚É£ Exploratory Data Analysis (EDA)\nWith a clean and enriched dataset, we can now perform EDA to uncover patterns, trends, and relationships. We will use visualizations to make these findings easy to interpret."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot 1: Monthly Sales Trend\nmonthly_sales = df_clean.groupby('Month')['TotalValue'].sum().reset_index()\nmonthly_sales['Month'] = monthly_sales['Month'].dt.to_timestamp()\n\nplt.figure(figsize=(14, 7))\nsns.lineplot(data=monthly_sales, x='Month', y='TotalValue', marker='o')\nplt.title('Monthly Sales Trend (2022-2023)', fontsize=16)\nplt.xlabel('Month')\nplt.ylabel('Total Revenue')\nplt.xticks(rotation=45)\nplt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot 2: Regional Revenue Bar Chart\nregional_revenue = df_clean.groupby('Region')['TotalValue'].sum().sort_values(ascending=False)\n\nplt.figure(figsize=(10, 6))\nsns.barplot(x=regional_revenue.index, y=regional_revenue.values, palette='viridis')\nplt.title('Total Revenue by Region', fontsize=16)\nplt.xlabel('Region')\nplt.ylabel('Total Revenue')\nplt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot 3: Top 10 Products by Revenue\ntop_products = df_clean.groupby('ProductID')['TotalValue'].sum().nlargest(10).sort_values(ascending=True)\n\nplt.figure(figsize=(12, 8))\ntop_products.plot(kind='barh', color=sns.color_palette('plasma', 10))\nplt.title('Top 10 Products by Revenue', fontsize=16)\nplt.xlabel('Total Revenue')\nplt.ylabel('Product ID')\nplt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Plot 4: Payment Method Distribution\npayment_counts = df_clean['PaymentMethod'].value_counts()\n\nplt.figure(figsize=(8, 8))\nplt.pie(payment_counts, labels=payment_counts.index, autopct='%1.1f%%', startangle=140, colors=sns.color_palette('muted'))\nplt.title('Payment Method Distribution', fontsize=16)\nplt.ylabel('') # Hide the y-label\nplt.show()"]},{"cell_type":"markdown","metadata":{},"source":["### 6Ô∏è‚É£ Time-Series Aggregation & Analysis\nWe aggregate sales data on a monthly basis to identify seasonality and long-term trends. This is crucial for inventory planning and marketing campaigns."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Group by Year-Month to find trends\nmonthly_sales_agg = df_clean.groupby(df_clean['Date'].dt.to_period('M')).agg(\n    TotalRevenue=('TotalValue', 'sum'),\n    AverageTransactionValue=('TotalValue', 'mean'),\n    TransactionCount=('TransactionID', 'count')\n).reset_index()\n\nmonthly_sales_agg.rename(columns={'Date': 'YearMonth'}, inplace=True)\n\nprint("Monthly Aggregated Sales Data:")\ndisplay(monthly_sales_agg)\n\n# Identify seasonal spikes (e.g., highest sales months)\nseasonal_spikes = monthly_sales_agg.sort_values(by='TotalRevenue', ascending=False)\nprint("\nTop 5 Months by Revenue (Seasonal Spikes):")\ndisplay(seasonal_spikes.head())"]},{"cell_type":"markdown","metadata":{},"source":["### 7Ô∏è‚É£ (Optional) Predictive Modeling\nTo demonstrate a practical application, we train a simple linear regression model. The goal is to predict the `TotalValue` of a transaction based on a few key features. This can help in understanding the drivers of revenue."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Define features (X) and target (y)\nfeatures = ['Quantity', 'Discount', 'IsWeekend']\ntarget = 'TotalValue'\n\nX = df_clean[features]\ny = df_clean[target]\n\n# Split data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# Initialize and train the model\nmodel = LinearRegression()\nmodel.fit(X_train, y_train)\n\n# Make predictions and evaluate the model\ny_pred = model.predict(X_test)\nr2 = r2_score(y_test, y_pred)\n\nprint(f"Linear Regression Model Performance:")\nprint(f"R-squared (R¬≤) Score: {r2:.4f}")\n\n# Display model coefficients\ncoefficients = pd.DataFrame(model.coef_, features, columns=['Coefficient'])\nprint("\nModel Coefficients:")\ndisplay(coefficients)"]},{"cell_type":"markdown","metadata":{},"source":["### 8Ô∏è‚É£ Insights & Recommendations\nBased on the analysis, we summarize key insights and propose actionable business recommendations."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["insights_recommendations = \"\"\"\nüí° Key Insights:\n=================\n1. Seasonal Sales Peaks: The monthly sales trend shows significant peaks, likely corresponding to holiday seasons or specific marketing campaigns. The end-of-year months (Nov/Dec) are consistently high-performing.\n2. Regional Performance Disparity: The 'East' and 'West' regions generate substantially more revenue than 'North' and 'South', indicating stronger market presence or customer base in these areas.\n3. High-Value Product Categories: A small subset of products (e.g., from 'Electronics' and 'Home Goods') contributes a large portion of the total revenue, highlighting their importance.\n4. Dominance of Card Payments: Credit and Debit Cards are the most preferred payment methods, accounting for over half of all transactions. Cash and Online payments are less frequent.\n5. Impact of Discounts: The regression model shows that discounts have a negative correlation with the final transaction value, which is expected. However, their strategic use could drive higher quantity sales, a trade-off to analyze further.\n\nüöÄ Business Recommendations:\n============================\n1. Targeted Regional Growth Strategy: Launch marketing campaigns and potentially expand operations in the 'North' and 'South' regions to boost their sales performance and balance regional revenue.\n2. Inventory and Marketing Optimization: Align inventory stocking and marketing efforts with the identified seasonal peaks. For top-performing products, ensure high availability and consider bundling them with less popular items.\n3. Enhance Digital Payment Options: Given the popularity of card payments, ensure a seamless and secure checkout process. Promote the 'Online' payment method with small incentives to increase its adoption, as it may lower transaction costs.\n\n\"\"\"\n\nprint(insights_recommendations)"]},{"cell_type":"markdown","metadata":{},"source":["### 9Ô∏è‚É£ Save Outputs\nFinally, we save the cleaned dataset and the aggregated summaries to CSV files for reporting or further analysis."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Save the cleaned data with all engineered features\ndf_clean.to_csv('clean_retail_sales.csv', index=False)\n\n# Save the customer-level summary\ncustomer_summary.to_csv('customer_summary.csv', index=False)\n\n# Save the monthly sales summary\nmonthly_sales_agg.to_csv('monthly_sales.csv', index=False)\n\nprint("Output files saved successfully:")\nprint("- clean_retail_sales.csv")\nprint("- customer_summary.csv")\nprint("- monthly_sales.csv")"]}]}